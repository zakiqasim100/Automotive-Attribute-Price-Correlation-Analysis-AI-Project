{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b2dea7-c1bb-4925-bfaa-666de40a712b",
   "metadata": {},
   "source": [
    "# Neural Network Model using TensorFlow and Keras to perform Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f7e6d2a-788a-4924-a3bc-ad93b1e807e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1031/1031\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 242273632.0000 - val_loss: 261659424.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m1031/1031\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 245472096.0000 - val_loss: 256638512.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m1031/1031\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 233595712.0000 - val_loss: 249454576.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m1031/1031\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 222788656.0000 - val_loss: 240709248.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m1031/1031\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 219170768.0000 - val_loss: 230782512.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m1031/1031\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 205360720.0000 - val_loss: 219923952.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m1031/1031\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 198633472.0000 - val_loss: 208425552.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m1031/1031\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 184290912.0000 - val_loss: 196537152.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m1031/1031\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 180583184.0000 - val_loss: 184615360.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m1031/1031\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 161698656.0000 - val_loss: 172815088.0000\n",
      "Train Loss: 156839744.0\n",
      "Test Loss: 165168000.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data = pd.read_csv(\"vehicles_dataset_from_advertisement.csv\")\n",
    "\n",
    "# Select specific columns as features and target variable\n",
    "features = ['model_year', 'odometer', 'condition', 'cylinders', 'fuel', 'transmission', 'type', 'paint_color']\n",
    "target = 'price'\n",
    "\n",
    "X = data[features]  # Features\n",
    "y = data[target]    # Target variable\n",
    "\n",
    "# Data Preprocessing\n",
    "# Convert categorical variables into numerical representations (e.g., one-hot encoding)\n",
    "X = pd.get_dummies(X, columns=['condition', 'fuel', 'transmission', 'type', 'paint_color'])\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=MeanSquaredError())\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "train_loss = model.evaluate(X_train_scaled, y_train, verbose=0)\n",
    "test_loss = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "\n",
    "print(f\"Train Loss: {train_loss}\")\n",
    "print(f\"Test Loss: {test_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec6eb65-7c0c-4dc9-b80d-bcdb70aa711d",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c2488c6-1658-41de-8db7-79f7fecba8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trees (estimators) in Random Forest: 100\n",
      "Train Loss (Random Forest Regression): 4853161.560541999\n",
      "Test Loss (Random Forest Regression): 32926363.587604124\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data = pd.read_csv(\"vehicles_dataset_from_advertisement.csv\")\n",
    "\n",
    "# Select specific columns as features and target variable\n",
    "features = ['model_year', 'odometer', 'condition', 'cylinders', 'fuel', 'transmission', 'type', 'paint_color']\n",
    "target = 'price'\n",
    "\n",
    "X = data[features]  # Features\n",
    "y = data[target]    # Target variable\n",
    "\n",
    "# Data Preprocessing\n",
    "# Convert categorical variables into numerical representations (e.g., one-hot encoding)\n",
    "X = pd.get_dummies(X, columns=['condition', 'fuel', 'transmission', 'type', 'paint_color'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest Regression model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Number of trees in the Random Forest model\n",
    "num_trees = len(rf_model.estimators_)\n",
    "\n",
    "# Evaluate the model\n",
    "train_loss_rf = mean_squared_error(y_train, y_train_pred)\n",
    "test_loss_rf = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Number of trees (estimators) in Random Forest: {num_trees}\")\n",
    "print(f\"Train Loss (Random Forest Regression): {train_loss_rf}\")\n",
    "print(f\"Test Loss (Random Forest Regression): {test_loss_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d89fe2f-508c-414d-bd13-d56948fbc360",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0f4bc45-41c0-4fa9-9568-249fc1334ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss (Linear Regression): 50733877.99016937\n",
      "Test Loss (Linear Regression): 56897539.181750946\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data = pd.read_csv(\"vehicles_dataset_from_advertisement.csv\")\n",
    "\n",
    "# Select specific columns as features and target variable\n",
    "features = ['model_year', 'odometer', 'condition', 'cylinders', 'fuel', 'transmission', 'type', 'paint_color']\n",
    "target = 'price'\n",
    "\n",
    "X = data[features]  # Features\n",
    "y = data[target]    # Target variable\n",
    "\n",
    "# Data Preprocessing\n",
    "# Convert categorical variables into numerical representations (e.g., one-hot encoding)\n",
    "X = pd.get_dummies(X, columns=['condition', 'fuel', 'transmission', 'type', 'paint_color'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = lr_model.predict(X_train)\n",
    "y_test_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "train_loss_lr = mean_squared_error(y_train, y_train_pred)\n",
    "test_loss_lr = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train Loss (Linear Regression): {train_loss_lr}\")\n",
    "print(f\"Test Loss (Linear Regression): {test_loss_lr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b6ca9-c5f2-4766-906a-c411b03a28f9",
   "metadata": {},
   "source": [
    "#### Training Loss: \n",
    "This represents the error of the model on the training dataset. It is calculated as the difference between the actual target values and the predicted values of the model, typically using a loss function (e.g., mean squared error for regression problems). A lower training loss indicates that the model is fitting well to the training data.\n",
    "#### Testing Loss: \n",
    "This represents the error of the model on the testing dataset, which contains data that the model has not seen during training. It is calculated in the same way as the training loss. The testing loss provides an estimate of how well the model generalizes to new, unseen data. A similar (but not necessarily identical) testing loss compared to the training loss suggests that the model is not overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa04edc-bbb5-45a6-864e-52f92408231c",
   "metadata": {},
   "source": [
    "# Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88e22f4d-4ff4-4c37-b31e-e30b7349d0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 539748.4444241101\n",
      "Test Loss: 84770266.99811314\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"vehicles_dataset_from_advertisement.csv\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Selecting features and target variable\n",
    "X = data[['model_year', 'odometer', 'condition', 'cylinders', 'fuel', 'transmission', 'type', 'paint_color']]\n",
    "y = data['price']\n",
    "\n",
    "# One-hot encoding categorical variables\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Decision Tree Regression model\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = dt_model.predict(X_train)\n",
    "y_test_pred = dt_model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "train_loss = mean_squared_error(y_train, y_train_pred)\n",
    "test_loss = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"Train Loss:\", train_loss)\n",
    "print(\"Test Loss:\", test_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee3e082-6a31-4f5e-a984-5b123c33ff09",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2156b97f-54b4-4f67-b97c-9fbbc88b126a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 40811233.93412305\n",
      "Test Loss: 39573611.107459165\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"vehicles_dataset_from_advertisement.csv\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Select features and target variable\n",
    "X = data[['model_year', 'odometer', 'condition', 'cylinders', 'fuel', 'transmission', 'type', 'paint_color']]\n",
    "y = data['price']\n",
    "\n",
    "# Perform one-hot encoding for categorical features\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate the Gradient Boosting Regression model\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = gb_model.predict(X_train)\n",
    "y_test_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "train_loss = mean_squared_error(y_train, y_train_pred)\n",
    "test_loss = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"Train Loss:\", train_loss)\n",
    "print(\"Test Loss:\", test_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef4c509-c459-4d51-a562-c4de2fcd5622",
   "metadata": {},
   "source": [
    "# Support Vector Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b96ed82d-d4bc-4485-8238-3cdbece21c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 129060095.99088883\n",
      "Test Loss: 133831685.37310076\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"vehicles_dataset_from_advertisement.csv\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Select features and target variable\n",
    "X = data[['model_year', 'odometer', 'condition', 'cylinders', 'fuel', 'transmission', 'type', 'paint_color']]\n",
    "y = data['price']\n",
    "\n",
    "# Perform one-hot encoding for categorical features\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate the SVR model\n",
    "svr_model = SVR()\n",
    "\n",
    "# Train the model\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = svr_model.predict(X_train)\n",
    "y_test_pred = svr_model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "train_loss = mean_squared_error(y_train, y_train_pred)\n",
    "test_loss = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"Train Loss:\", train_loss)\n",
    "print(\"Test Loss:\", test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6580f63f-4d37-48ed-919a-7291470340e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
